{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd08d3-878c-4f54-879c-9b260510b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2a47ef-15ec-4181-86e2-8351e59c1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from altair_saver import save\n",
    "import pandas as pd\n",
    "from util import load_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcbd17-4d0a-48f2-a2b4-054a1cac97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df, val_df, test_df = load_experiment(\"dataset_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9133d02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "baseline_df[\"model\"] = \"Production Ranker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfc8ea0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model2name = {\n",
    "    \"Neural PBM - Unbiased\": \"PBM - True Bias\",\n",
    "    \"Neural PBM - Biased\": \"PBM - Naive\",\n",
    "    \"Neural PBM - Estimated bias\": \"PBM - Estimated Bias\",\n",
    "    \"Pointwise IPS - Unbiased\": \"Point. IPS - True Bias\",\n",
    "    \"Pointwise IPS - Biased\": \"Point. IPS / PBM - Naive\",\n",
    "}\n",
    "\n",
    "test_df.model = test_df.model.map(model2name)\n",
    "test_df = test_df[test_df.model != \"PBM - Naive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a8ea8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot(dataset_df, legend=True, width=320, height=125, metric=\"average_relevant_position\", title=\"\", y=[0, 1.0], clip=False, label_y=True, label_x=True): \n",
    "\n",
    "    lines = alt.Chart(dataset_df, width=width, height=height, title=title).mark_line(clip=clip).encode(\n",
    "        x=alt.X(\"n_sessions\", scale=alt.Scale(type=\"log\"), title=\"Number of Train Queries\" if label_x else None, axis=alt.Axis(format=\"~s\")),\n",
    "        y=alt.Y(f\"mean({metric})\", scale=alt.Scale(zero=False, domain=y), title=metric if label_y else None),\n",
    "        color=alt.Color(\"model\", legend=None),\n",
    "        tooltip=[f\"count({metric})\", \"n_sessions\", f\"mean({metric})\"]\n",
    "    )\n",
    "\n",
    "    marks = alt.Chart(dataset_df).mark_point(clip=clip, size=50).encode(\n",
    "        x=alt.X(\"n_sessions\", scale=alt.Scale(type=\"log\"), title=\"Number of Train Queries\", axis=alt.Axis(format=\"~s\")),\n",
    "        y=alt.Y(f\"mean({metric})\", scale=alt.Scale(zero=False)),\n",
    "        shape=alt.Shape(\"model\"),\n",
    "        color=alt.Color(\"model\") if legend else alt.Color(\"model\", legend=None),\n",
    "        tooltip=[f\"count({metric})\", \"n_sessions\", f\"mean({metric})\"]\n",
    "    )\n",
    "\n",
    "    ci = alt.Chart(dataset_df).mark_errorband(opacity=0.5, clip=clip).encode(\n",
    "        x=alt.X(\"n_sessions\", scale=alt.Scale(type=\"log\"), title=\"Number of Train Queries\", axis=alt.Axis(format=\"~s\")),\n",
    "        y=alt.Y(metric, scale=alt.Scale(zero=False)),\n",
    "        color=alt.Color(\"model\", legend=None),\n",
    "    )\n",
    "\n",
    "    return alt.layer(\n",
    "        lines,\n",
    "        marks,\n",
    "        ci\n",
    "    ).resolve_scale(color=\"independent\", shape=\"independent\")\n",
    "\n",
    "yahoo_df = pd.concat([test_df[test_df.dataset == \"Yahoo\"], baseline_df[baseline_df.dataset == \"Yahoo\"]])\n",
    "istella_df = pd.concat([test_df[test_df.dataset == \"Istella-S\"], baseline_df[baseline_df.dataset == \"Istella-S\"]])\n",
    "mslr_df = pd.concat([test_df[test_df.dataset == \"MSLR-Web30K\"], baseline_df[baseline_df.dataset == \"MSLR-Web30K\"]])\n",
    "synthetic_df = pd.concat([test_df[test_df.dataset == \"Synthetic\"], baseline_df[baseline_df.dataset == \"Synthetic\"]])\n",
    "\n",
    "chart = (\n",
    "    (plot(mslr_df, legend=False, metric=\"nDCG@10\", title=\"MSLR-WEB30K\", y=[0.25, .5], clip=True, label_y=True, label_x=False) |\n",
    "    plot(istella_df, legend=True, metric=\"nDCG@10\", title=\"Istella\", y=[0.60, 0.75], clip=True, label_y=False, label_x=False)) &\n",
    "    (plot(yahoo_df, legend=False, metric=\"nDCG@10\", title=\"Yahoo\", y=[0.6, 0.75], clip=True, label_y=True) |\n",
    "    plot(synthetic_df, legend=False, metric=\"nDCG@10\", title=\"Synthetic\", y=[0, 1.0], clip=True, label_y=False))\n",
    ").configure_legend(\n",
    "    orient=\"right\",\n",
    "    title=None,\n",
    "    labelFont=\"serif\",\n",
    "    labelFontSize=14,\n",
    "    columnPadding=20,\n",
    ").configure_title(\n",
    "    fontSize=14,\n",
    "    fontWeight=\"normal\",\n",
    "    font=\"serif\"\n",
    ").configure_axis(\n",
    "    titlePadding=10,\n",
    "    titleFontSize=14,\n",
    "    titleFontWeight=\"normal\",\n",
    "    titleFont=\"serif\",\n",
    "    labelFontSize=10,\n",
    "    labelFontWeight=\"normal\",\n",
    "    labelFont=\"serif\",\n",
    "    tickCount=6\n",
    ")\n",
    "\n",
    "save(chart, \"figures/results.pdf\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095d5ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Statsistical Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9226a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27f852",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df.dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70624d8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "source = test_df[test_df.n_sessions == 100_000_000].groupby([\"model\", \"dataset\"])[[\"nDCG@5\", \"nDCG@10\", \"ARP\"]].agg([\"mean\", \"std\"]).round(3)\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da266186",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = \"MSLR-Web30K\"\n",
    "metric = \"nDCG@10\"\n",
    "n_sessions = 100000000\n",
    "\n",
    "for dataset in test_df.dataset.unique():\n",
    "    columns = [\"model\", \"random_state\", metric]\n",
    "\n",
    "    source = test_df[(test_df.dataset == dataset) & (test_df.n_sessions == n_sessions)].sort_values(columns)[columns]\n",
    "    source.head()\n",
    "\n",
    "    from scipy import stats\n",
    "    import statsmodels.stats.multicomp as mc\n",
    "\n",
    "    comparison = mc.MultiComparison(source[metric], source[\"model\"])\n",
    "    tbl, a1, a2 = comparison.allpairtest(stats.ttest_ind, method= \"bonf\", alpha=0.0001)\n",
    "\n",
    "    print(\"\\n\", dataset)\n",
    "    print(tbl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}