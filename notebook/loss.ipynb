{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1d612-de61-4967-9c98-8ed4c7eb7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc0213d-86d9-4513-a8d1-2fd06f630003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from altair_saver import save\n",
    "from src.loss import BinaryCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ded375-8aa8-4b88-8c41-f0177e098ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from typing import Optional\n",
    "\n",
    "class BinaryCrossEntropyWithLogits(nn.Module):\n",
    "    def forward(\n",
    "        self,\n",
    "        y_predict: torch.Tensor,\n",
    "        y_true: torch.Tensor,\n",
    "        n: torch.Tensor,\n",
    "        position_bias: Optional[torch.Tensor] = None,\n",
    "        clip: Optional[float] = None,\n",
    "        eps: float = 1e-10,\n",
    "    ) -> torch.float:\n",
    "        \"\"\"\n",
    "        Binary Cross-Entropy with IPS as in Bekker2019, Saito2020, Oosterhuis2022\n",
    "        https://arxiv.org/pdf/2203.17118.pdf\n",
    "        https://arxiv.org/pdf/1909.03601.pdf\n",
    "\n",
    "        Args:\n",
    "            y_predict: Tensor of size (n_batch, n_results) with predicted relevance\n",
    "            y_true: Tensor of size (n_batch, n_results) with ground_truth scores\n",
    "            position_bias: Tensor of size (n_results) with propensities per rank\n",
    "            clip: Min propensity used to clip position_bias\n",
    "            eps: Min value to avoid ln(0) = -inf\n",
    "\n",
    "        Returns:\n",
    "            Mean aggregated loss for the given batch\n",
    "        \"\"\"\n",
    "        if position_bias is None:\n",
    "            position_bias = torch.ones_like(y_true)\n",
    "\n",
    "        if clip is not None:\n",
    "            position_bias = position_bias.clip(min=clip)\n",
    "\n",
    "        position_bias = position_bias.type_as(y_predict)\n",
    "\n",
    "        loss = -(\n",
    "            (y_true / position_bias) * torch.log(y_predict.clip(min=eps))\n",
    "            + (1 - (y_true / position_bias)) * torch.log((1 - y_predict).clip(min=eps))\n",
    "        )\n",
    "\n",
    "        return loss.sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19a4a8-6e38-485d-a25c-d6ac5d38fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ips_fn = BinaryCrossEntropyWithLogits()\n",
    "o = 1 / torch.arange(1, 11)\n",
    "y = 0.5\n",
    "rows = []\n",
    "\n",
    "for o_k in o:\n",
    "    c_d = y * o_k\n",
    "    c_d = c_d.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    for y_predict in torch.arange(0, 101) / 100:\n",
    "        y_predict = y_predict.unsqueeze(0).unsqueeze(0)\n",
    "        n = torch.tensor([1])\n",
    "        \n",
    "        loss = ips_fn(y_predict, c_d, n, o_k.unsqueeze(0))\n",
    "        rows.append({\n",
    "            \"examination\": float(o_k),\n",
    "            \"y_predict\": float(y_predict[[0]]),\n",
    "            \"y_true\": y,\n",
    "            \"loss\": float(loss),\n",
    "            \"model\": \"IPS\"\n",
    "        })\n",
    "        \n",
    "ips_df = pd.DataFrame(rows)\n",
    "ips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9b42f-c76f-44c1-a175-f179df968056",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_fn = BinaryCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefbacd7-fff8-4926-b096-a030af46d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = 1 / torch.arange(1, 11)\n",
    "y = 0.5\n",
    "rows = []\n",
    "\n",
    "for o_k in o:\n",
    "    c_d = y * o_k\n",
    "    c_d = c_d.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    for y_predict in torch.arange(0, 101) / 100:\n",
    "        c_predict = (y_predict * o_k).unsqueeze(0).unsqueeze(0)\n",
    "        n = torch.tensor([1])\n",
    "        \n",
    "        loss = cm_fn(c_predict, c_d, n)\n",
    "        rows.append({\n",
    "            \"examination\": float(o_k),\n",
    "            \"y_predict\": float(y_predict),\n",
    "            \"y_true\": y,\n",
    "            \"loss\": float(loss),\n",
    "            \"model\": \"CM\"\n",
    "        })\n",
    "        \n",
    "cm_df = pd.DataFrame(rows)\n",
    "cm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d6e48-5cf6-4ee1-ad84-b04469f94da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = cm_df\n",
    "min_source = cm_df.sort_values([\"examination\", \"loss\"]).groupby([\"examination\"]).head(1)\n",
    "\n",
    "cm_chart = alt.Chart(source, width=300, height=175, title=\"Neural PBM\").mark_line(clip=True).encode(\n",
    "    x=alt.X(\"y_predict\", title=\"Estimated relevance P(天 = 1 | d)\"),\n",
    "    y=alt.Y(\"loss\", scale=alt.Scale(domain=(0, 2.0)), title=\"Loss\"),\n",
    "    color=alt.Color(\"examination:Q\", title=\"P(O = 1 | k)\")\n",
    ") + alt.Chart(min_source).mark_circle(size=40, opacity=1.0).encode(\n",
    "    x=\"y_predict\",\n",
    "    y=alt.Y(\"loss\"),\n",
    ")\n",
    "\n",
    "source = ips_df\n",
    "min_source = ips_df.sort_values([\"examination\", \"loss\"]).groupby([\"examination\"]).head(1)\n",
    "\n",
    "ips_chart = alt.Chart(source, width=300, height=175, title=\"Pointwise IPS\").mark_line(clip=True).encode(\n",
    "    x=alt.X(\"y_predict\", title=\"Estimated relevance P(天 = 1 | d)\"),\n",
    "    y=alt.Y(\"loss\", scale=alt.Scale(domain=(0, 2.0)), title=None),\n",
    "    color=alt.Color(\"examination:Q\")\n",
    ") + alt.Chart(min_source).mark_circle(size=40, opacity=1.0).encode(\n",
    "    x=\"y_predict\",\n",
    "    y=alt.Y(\"loss\"),\n",
    ")\n",
    "\n",
    "chart = (cm_chart | ips_chart).configure_legend(\n",
    "    orient=\"right\",\n",
    "    title=None,\n",
    "    labelFont=\"serif\",\n",
    "    labelFontSize=14,\n",
    "    titleFontSize=16,\n",
    "    titleFontWeight=\"normal\",\n",
    "    titleFont=\"serif\",\n",
    "    columnPadding=20,\n",
    "    gradientLength=155,\n",
    "    gradientThickness=15\n",
    ").configure_title(\n",
    "    fontSize=16,\n",
    "    fontWeight=\"normal\",\n",
    "    font=\"serif\"\n",
    ").configure_axis(\n",
    "    titlePadding=10,\n",
    "    titleFontSize=16,\n",
    "    titleFontWeight=\"normal\",\n",
    "    titleFont=\"serif\",\n",
    "    labelFontSize=14,\n",
    "    labelFontWeight=\"normal\",\n",
    "    labelFont=\"serif\",\n",
    "    tickCount=8,\n",
    "    tickBand=\"center\"\n",
    ")\n",
    "\n",
    "save(chart, \"figures/loss.pdf\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbc246-b2f9-44f2-9381-1db682247bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cm(x, y, o, name):\n",
    "    rows = []\n",
    "    epochs = 100\n",
    "    lr = 0.1\n",
    "    cm_fn = BinaryCrossEntropy()\n",
    "    c_d = y * o\n",
    "\n",
    "    for y_predict in torch.arange(0, 101) / 100:\n",
    "        y_predict = y_predict.repeat((2,))\n",
    "\n",
    "        c_predict = (y_predict * o)\n",
    "        n = torch.tensor([2])\n",
    "\n",
    "        loss = cm_fn(c_predict, c_d, n)\n",
    "        rows.append({\n",
    "            \"examination\": o.numpy(),\n",
    "            \"y_predict\": float(y_predict[0]),\n",
    "            \"y_true\": y.numpy(),\n",
    "            \"loss\": float(loss),\n",
    "            \"model\": name\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "    \n",
    "cm_item_a = train_cm(\n",
    "    x=torch.tensor([\n",
    "        [1, 0],\n",
    "    ]).float(),\n",
    "    y=torch.tensor([\n",
    "        0.1\n",
    "    ]),\n",
    "    o=torch.tensor([\n",
    "        [1.0],\n",
    "    ]),\n",
    "    name=\"y = 0.1, o = 1.0\"\n",
    ")\n",
    "\n",
    "cm_item_b = train_cm(\n",
    "    x=torch.tensor([\n",
    "        [1, 0],\n",
    "    ]).float(),\n",
    "    y=torch.tensor([\n",
    "        0.9\n",
    "    ]),\n",
    "    o=torch.tensor([\n",
    "        [0.1],\n",
    "    ]),\n",
    "    name=\"y = 0.8, o = 0.1\"\n",
    ")\n",
    "\n",
    "cm_item_combined = train_cm(\n",
    "    x=torch.tensor([\n",
    "        [1, 0],\n",
    "        [1, 0]\n",
    "    ]).float(),\n",
    "    y=torch.tensor([\n",
    "        0.1, 0.9\n",
    "    ]),\n",
    "    o=torch.tensor([\n",
    "        [1.0, 0.1],\n",
    "    ]),\n",
    "    name=\"Combined\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc3988-c26c-4b4d-99e3-dbeccdb32503",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.concat([cm_item_a, cm_item_b, cm_item_combined])\n",
    "min_source = source[[\"model\", \"y_predict\", \"loss\"]].sort_values([\"model\", \"loss\"]).groupby([\"model\"]).head(1)\n",
    "\n",
    "cm_chart = (alt.Chart(source, width=275, height=175, title=\"Neural PBM\").mark_line(clip=True).encode(\n",
    "    x=alt.X(\"y_predict\", title=\"Estimated relevance P(天 = 1 | d)\"),\n",
    "    y=alt.Y(\"loss\", scale=alt.Scale(domain=(0, 2.0)), title=\"Loss\"),\n",
    "    color=alt.Color(\"model\", legend=None),\n",
    "    strokeDash=alt.condition(\n",
    "        alt.datum.model == \"Combined\",\n",
    "        alt.value([0, 0]),  # dashed line: 5 pixels  dash + 5 pixels space\n",
    "        alt.value([2, 2]),  # solid line\n",
    "    )\n",
    ") + alt.Chart(min_source).mark_point(size=40, opacity=1.0).encode(\n",
    "    x=\"y_predict\",\n",
    "    y=alt.Y(\"loss\"),\n",
    "    color=alt.Color(\"model\", legend=None),\n",
    "    shape=alt.Shape(\"model\", legend=None),\n",
    "    tooltip=\"y_predict\"\n",
    ")).resolve_scale(\n",
    "    color=\"independent\",\n",
    "    shape=\"independent\"\n",
    ")\n",
    "\n",
    "cm_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb217c-2266-4b17-95b0-cf016cc17f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ips(x, y, o, name):\n",
    "    rows = []\n",
    "    epochs = 100\n",
    "    lr = 0.1\n",
    "    ips_fn = BinaryCrossEntropyWithLogits()\n",
    "    c_d = y * o\n",
    "\n",
    "    for y_predict in torch.arange(0, 101) / 100:\n",
    "        y_predict = y_predict.repeat((2,))\n",
    "\n",
    "        c_predict = (y_predict * o)\n",
    "        n = torch.tensor([2])\n",
    "\n",
    "        loss = ips_fn(y_predict, c_d, n, o)\n",
    "        rows.append({\n",
    "            \"examination\": o.numpy(),\n",
    "            \"y_predict\": float(y_predict[0]),\n",
    "            \"y_true\": y.numpy(),\n",
    "            \"loss\": float(loss),\n",
    "            \"model\": name\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "    \n",
    "ips_item_a = train_ips(\n",
    "    x=torch.tensor([\n",
    "        [1, 0],\n",
    "    ]).float(),\n",
    "    y=torch.tensor([\n",
    "        0.1\n",
    "    ]),\n",
    "    o=torch.tensor([\n",
    "        [1.0],\n",
    "    ]),\n",
    "    name=\"y = 0.1, o = 1.0\"\n",
    ")\n",
    "\n",
    "ips_item_b = train_ips(\n",
    "    x=torch.tensor([\n",
    "        [1, 0],\n",
    "    ]).float(),\n",
    "    y=torch.tensor([\n",
    "        0.9\n",
    "    ]),\n",
    "    o=torch.tensor([\n",
    "        [0.1],\n",
    "    ]),\n",
    "    name=\"y = 0.9, o = 0.1\"\n",
    ")\n",
    "\n",
    "ips_item_combined = train_ips(\n",
    "    x=torch.tensor([\n",
    "        [1, 0],\n",
    "        [1, 0]\n",
    "    ]).float(),\n",
    "    y=torch.tensor([\n",
    "        0.1, 0.9\n",
    "    ]),\n",
    "    o=torch.tensor([\n",
    "        [1.0, 0.1],\n",
    "    ]),\n",
    "    name=\"Combined\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77b3bd-c161-4f45-895d-43801bf246cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.concat([ips_item_a, ips_item_b, ips_item_combined])\n",
    "min_source = source[[\"model\", \"y_predict\", \"loss\"]].sort_values([\"model\", \"loss\"]).groupby([\"model\"]).head(1)\n",
    "\n",
    "ips_chart = (alt.Chart(source, width=275, height=175, title=\"Pointwise IPS\").mark_line(clip=True).encode(\n",
    "    x=alt.X(\"y_predict\", title=\"Estimated relevance P(天 = 1 | d)\"),\n",
    "    y=alt.Y(\"loss\", scale=alt.Scale(domain=(0, 2.0)), title=None),\n",
    "    color=alt.Color(\"model\", legend=None),\n",
    "    strokeDash=alt.condition(\n",
    "        alt.datum.model == \"Combined\",\n",
    "        alt.value([0, 0]),  # dashed line: 5 pixels  dash + 5 pixels space\n",
    "        alt.value([2, 2]),  # solid line\n",
    "    )\n",
    ") + alt.Chart(min_source).mark_point(size=40, opacity=1.0).encode(\n",
    "    x=\"y_predict\",\n",
    "    y=alt.Y(\"loss\"),\n",
    "    color=\"model\",\n",
    "    shape=\"model\",\n",
    "    tooltip=\"loss\"\n",
    ")).resolve_scale(\n",
    "    color=\"independent\",\n",
    "    shape=\"independent\"\n",
    ")\n",
    "\n",
    "ips_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec33c981-01dc-4662-b953-c5ba7a9c40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = (cm_chart | ips_chart).configure_legend(\n",
    "    orient=\"right\",\n",
    "    title=None,\n",
    "    labelFont=\"serif\",\n",
    "    labelFontSize=16,\n",
    "    titleFontSize=16,\n",
    "    titleFontWeight=\"normal\",\n",
    "    titleFont=\"serif\",\n",
    "    columnPadding=20,\n",
    "    gradientLength=155,\n",
    "    gradientThickness=15\n",
    ").configure_title(\n",
    "    fontSize=16,\n",
    "    fontWeight=\"normal\",\n",
    "    font=\"serif\"\n",
    ").configure_axis(\n",
    "    titlePadding=10,\n",
    "    titleFontSize=16,\n",
    "    titleFontWeight=\"normal\",\n",
    "    titleFont=\"serif\",\n",
    "    labelFontSize=14,\n",
    "    labelFontWeight=\"normal\",\n",
    "    labelFont=\"serif\",\n",
    "    tickCount=8,\n",
    "    tickBand=\"center\"\n",
    ")\n",
    "\n",
    "save(chart, \"figures/loss_bias.pdf\")\n",
    "chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
