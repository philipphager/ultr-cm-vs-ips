defaults:
  - _self_
  - data: mslr10k
  - baseline: lgbm
  - simulation: graded-pbm
  - model: ips

experiment:
  name: default

random_state: 0

trainer:
  _target_: pytorch_lightning.Trainer
  max_epochs: 100
  accelerator: auto
  # val_check_interval: 10_000 # Evaluate every 500k clicks, use when not aggregating clicks
  logger:
    - _target_: src.logger.LocalLogger
  callbacks:
    -
     _target_: pytorch_lightning.callbacks.EarlyStopping
     monitor: val_loss
     patience: 5

train_loader:
  _target_: torch.utils.data.DataLoader
  dataset: ???
  batch_size: 50
  shuffle: true

val_test_loader:
  _target_: torch.utils.data.DataLoader
  dataset: ???
  batch_size: 500
  shuffle: false


hydra:
  job:
    chdir: True
  output_subdir: .
  run:
    dir: results/${experiment.name}
  sweep:
    dir: results/${experiment.name}
    subdir: ${hydra.job.override_dirname}
